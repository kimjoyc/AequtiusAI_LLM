# -*- coding: utf-8 -*-
"""
free_colab-llm.ipynb

This script is designed to interact with the Ollama chat model for summarization tasks.
It demonstrates how to use the Ollama API to generate summaries based on user queries and filtered API responses.
This script also queries an external API and performs searches within the results based on specific criteria.
The goal is to generate and print summaries for filtered API results.

Original file is located at:
    https://colab.research.google.com/drive/1nnAM17NJNLWqhzvS1ofRmwdIOk6NXDJb
"""

# Step 1: Install Ollama

# The following command installs Ollama on the system. Ollama is a tool to interact with AI models for various tasks like summarization.
# Install Ollama from the provided installation script URL.
!curl -fsSL https://ollama.com/install.sh | sh

"""# Install Ollama Python Interface

# This step installs the Python interface for Ollama, which allows you to interact with Ollama models programmatically from Python.
# It installs the necessary package that provides functions like ollama.chat to interact with AI models.
"""

# Installing Ollama Python interface to interact with models
! pip install ollama

"""# Start Ollama Server Using subprocess (for Google Colab)

# In Google Colab or any environment where processes need to be managed programmatically, we use subprocess to start the Ollama server.
# The subprocess is used to run external commands from Python and is important for environments like Colab where background processes are needed.
"""

import subprocess

# Start the Ollama server in the background as a subprocess
process = subprocess.Popen(['ollama', 'serve'])

"""# Pull Ollama Model: gemma version 2b

# The next step pulls the Ollama model `gemma:2b` from the Ollama model library. 
# This model will be used to generate summaries from the queried text later.
"""

# Pull the `gemma:2b` model from Ollama's library for further use in the script
! ollama pull gemma:2b

"""## Ollama Function Documentation

# This section explains how to interact with the Ollama chat model `gemma:2b`.
# It involves sending a user-defined prompt along with text from API results to generate a summary.

# Example Usage:

# Assume we have extracted some JSON data from an API (`endpoint_data_json`). 
# We want to query specific information about California wills. 
# The `user_input_prompt` will guide the summarization task based on the relevant data.

# A function `ollama_func` will be used to send the query to Ollama and receive a summary.
"""

import ollama  # Importing the Ollama library

def ollama_func(queried_text, user_input_prompt):
    """
    This function interacts with the Ollama chat model to generate a summary based on the user input prompt
    and the queried text passed to it.

    Arguments:
    - queried_text (str): The text extracted from API data that will be used as context for summarization.
    - user_input_prompt (str): The user's query or request to guide the summarization task.

    Returns:
    - str: The summary generated by the Ollama chat model based on the provided inputs.
    """

    # Construct the message to be sent to the Ollama model.
    message = {
        'role': 'user',  # The role is 'user', as the input comes from the user
        'content': f"{user_input_prompt} {queried_text}",  # Combine the prompt with the relevant text
    }

    # Send the constructed message to the Ollama model and receive the response.
    response = ollama.chat(model='gemma:2b', messages=[message])

    # Extract the summary from the response.
    summary = response['message']['content']

    # Return the summary text
    return summary

"""## Python Imports Explanation

### `requests` Library

# `requests` is a library for making HTTP requests. It is used here to query external APIs and retrieve data.

### `numpy` Library

# `numpy` is a core library for numerical computing in Python. It provides support for arrays, matrices, and complex mathematical functions.

### `itertools.chain` Function

# The `itertools.chain` function is used to combine multiple iterables into a single iterable. 
# It is useful for merging data without creating unnecessary intermediate data structures.
"""

import requests
import numpy as np
from itertools import chain

"""## `query_api_and_search` Function Explanation

# This function queries an API and optionally filters the results based on a search term.
# It gives flexibility to either filter the results or return unfiltered data based on user input.
"""

def query_api_and_search(endpoint_url, search_strings=None):
    """
    This function queries an API endpoint and searches through its 'results' for values containing a specified search string.
    If no search string is provided, the function will return unfiltered results.

    Arguments:
    - endpoint_url (str): The URL of the API endpoint to query.
    - search_strings (list, optional): List of strings to search for within the API results.

    Returns:
    - list: A list of values from the API results that contain all the specified search strings, or unfiltered results.
    """
    try:
        # Perform the GET request to the API endpoint.
        response = requests.get(endpoint_url, headers={
            "Authorization": "e217cca68906c4490a35881616ab40d1907c501c",  # Example authorization token
            "Accept": "application/json"  # Indicate we expect a JSON response
        })
        response.raise_for_status()  # Raise an exception if the request fails

        # Parse the JSON response
        data = response.json()

        if 'results' in data:
            if search_strings:
                # Filter results based on the search string.
                filtered_results = []
                for result in data['results']:
                    # Check if any value contains all the search strings
                    if all(search_string.lower() in str(value).lower()
                           for search_string in search_strings for value in result.values()):
                        # If a match is found, add the result values to the filtered list
                        filtered_results.extend(result.values())

                return filtered_results
            else:
                # Return all values from 'results' if no search string is provided
                unfiltered_results = []
                for result in data['results']:
                    unfiltered_results.extend(result.values())

                return unfiltered_results

        else:
            print("No 'results' found in the JSON response.")
            return []

    except requests.exceptions.RequestException as e:
        # Catch and print any errors that occur during the API request
        print(f"Error querying API: {e}")
        return []

"""# Function Documentation: `get_summary_each_endpoint(filtered_results)`

## Overview

# This function retrieves a summary from Ollama based on the filtered API results.

## Parameters

# - `filtered_results` (list): A list of dictionaries containing the filtered data obtained from the API endpoint.

## Returns

# - `str`: A summary generated by the Ollama chat model.

## Functionality

# 1. Converts the filtered results into a string format by joining all the dictionary values.
# 2. Sends the concatenated text along with a prompt to the Ollama model for summarization.
# 3. Handles errors gracefully with a try-except block.
"""

def get_summary(results, user_input_prompt="Provide information:"):
    """
    This function generates a summary using the Ollama chat model based on the filtered results from the API.
    The filtered results are concatenated into a single string before sending to the model.

    Arguments:
    - results (list): The filtered API results.
    - user_input_prompt (str): The prompt that guides the summarization task. Default is "Provide information:".

    Returns:
    - str: The summary generated by the Ollama chat model.
    """
    try:
        # Concatenate the results into a single string
        concatenated_text = ' '.join(str(element) for element in results)
        
        # Get the summary from Ollama
        summary = ollama_func(concatenated_text, user_input_prompt)
        
        # Return the generated summary
        return summary

    except Exception as e:
        # Print any error that occurs and return None
        print(f"Error in get_summary_each_endpoint: {e}")
        return None

def main():
    """
    The main function queries API endpoints, filters results, and generates summaries using Ollama.

    The function:
    1. Queries an API root URL to retrieve available endpoints.
    2. Iterates through these endpoints and filters results based on a search term.
    3. For each filtered set of results, a summary is generated using the Ollama model.
    4. The summaries are printed out and consolidated.
    """

    # Define the base URL for querying the API
    api_root_url = "https://www.courtlistener.com/api/rest/v3/"

    try:
        # Query the root API URL for available endpoints
        response = requests.get(api_root_url)
        root_dict_endpoints = response.json()

        filt_dict = {}

        # Iterate through each endpoint to query and filter results
        for j, i in root_dict_endpoints.items():
            api_endpoint = i  # Endpoint URL
            search_term = ['California', 'Will']  # Example search terms for filtering

            # Query and filter results from the API
            filtered_results = query_api_and_search(api_endpoint, search_term)

            if filtered_results:
                # If filtered results are found, generate a summary using Ollama
                summary = get_summary(filtered_results, "Provide key document references related to California wills on the following ")
                print(summary)
                filt_dict[j] = summary
            else:
                continue

        # Consolidate summaries for all filtered results and generate a final summary
        print(get_summary(list(filt_dict.values()), "Draft a California will based on the following "))

    except requests.exceptions.RequestException as e:
        # Catch any errors that occur during the API request
        print(f"Error querying API: {e}")

# Start the script by calling the main function
if __name__ == "__main__":
    main()
